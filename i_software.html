<!DOCTYPE html>
<html>
  <head>
    <meta http-equiv="content-type" content="text/html; charset=UTF-8">
    <meta charset="utf-8">
    <!--[if lt IE 9]>
            <script src="http://html5shiv.googlecode.com/svn/trunk/html5.js"></script>
        <![endif]-->
    <link rel="stylesheet" href="style.css">
    <title>Peter Richtarik</title>
  </head>
  <body>
    <div id="page">
      <div id="header_wrapper">
        <div id="header" class="main">
          <script src="table_header.js"></script> </div>
      </div>
      <ul class="menu">
        <li><a href="index.html">News</a></li>
        <li><a href="i_oldnews.html">Old News</a></li>
        <li><a href="i_papers.html">Papers</a></li>
        <li><a href="i_talks.html">Talks</a></li>
        <li><a href="i_events.html">Events</a></li>
        <li><a href="i_seminar.html">Seminar</a></li>
        <li><a class="active" href="i_software.html">Code</a></li>
        <li><a href="i_team.html">Team</a></li>
        <li><a href="i_join.html">Join</a></li>
        <li><a href="i_bio.html">Bio</a></li>
        <li><a href="i_teaching.html">Teaching</a></li>
        <li><a href="i_consulting.html">Consulting</a></li>
      </ul>
      <div id="wrapper" class="main">
        <div id="content">
          <table width="831" border="1">
            <tbody>
              <tr>
                <td valign="top" align="center">REX (R Shiny)<br>
                </td>
                <td valign="top">Randomized EXchange algorithms,
                  implemented as web-based R Shiny apps, for <a
                    href="https://optdesign.shinyapps.io/od_rex/">computing





                    optimal design of experiments</a> and <a
                    href="https://optdesign.shinyapps.io/mvee_rex/">minimum





                    volume enclosing ellipsoids</a>. Based on this
                  paper.<br>
                </td>
              </tr>
              <tr>
                <td valign="top" align="center"><a
                    href="https://github.com/mehrhardt/spdhg">SPDHG</a><br>
                </td>
                <td valign="top">Stochastic Chambolle-Pock method (aka:
                  Stochastic Primal-Dual Hybrid Gradient method). Based
                  on this paper. See also this follow-up paper with
                  application to PET imaging.<br>
                </td>
              </tr>
              <tr>
                <td valign="top" align="center"><a
href="https://perso.telecom-paristech.fr/rgower/software/StochBFGS_dist-0.0.zip">StochBFGS</a><br>
                </td>
                <td valign="top">Stochastic (block) BFGS method for
                  solving the empirical risk minimization problem
                  with&nbsp; logistic loss and L2 regularizer. <a
                    href="http://arxiv.org/abs/1603.09649">Related
                    paper.</a><br>
                </td>
              </tr>
              <tr>
                <td valign="top" align="center"><a
                    href="code/InvRand.zip">Random Inverse</a><br>
                </td>
                <td valign="top">A suite of randomized methods for
                  inverting positive definite matrices implemented in
                  MATLAB. <a href="http://arxiv.org/abs/1602.01768">Related






                    paper.</a><br>
                </td>
              </tr>
              <tr>
                <td valign="top" align="center"><a
                    href="code/RandomLinearLab.zip">Random Linear Lab</a><br>
                </td>
                <td valign="top">A lab for testing and comparing
                  randomized methods for solving linear systems.
                  Implemented in MATLAB. <a
                    href="http://epubs.siam.org/doi/abs/10.1137/15M1025487">Related






                    paper</a>.<br>
                </td>
              </tr>
              <tr>
                <td valign="top" align="center"><a
                    href="https://github.com/gingsmith/cocoa">CoCoA</a><br>
                </td>
                <td valign="top">A framework for communication-efficient
                  distributed optimization for machine learning.<br>
                </td>
              </tr>
              <tr>
                <td align="center" width="146"><a href="code/approx.zip"><img
                      src="imgs/APPROX.png" width="146" height="55"></a></td>
                <td>
                  <p> Accelerated, Parallel and PROXimal coordinate
                    descent. This is an efficient C++ code based on <a
                      href="http://arxiv.org/abs/1312.5799">this paper.</a>
                    We also implement PCDM (parallel coordinate
                    descent), SDCA (stochastic dual coordinate ascent)
                    and AGD (Accelerated Gradient Descent). <br>
                    APPROX is implemented in <a
href="https://github.com/ofercoq/scikit-learn/tree/accelerated_coordinate_descent_for_elastic_net"><img
                        alt="APPROX @ scikit-learn"
                        src="imgs/scikit.png" width="100" border="0"
                        height="100"></a>. Choose option "accelerated"
                    when doing LASSO/elastic net.<br>
                  </p>
                </td>
              </tr>
              <tr>
                <td align="center" width="146"><a
                    href="http://mloss.org/software/view/556/">S2GD</a></td>
                <td>
                  <p> Semi-stochastic gradient descent method for fast
                    training of L2 regularized logistic regression. This
                    is an efficient C++ code (can be called from
                    MATLAB), based on <a
                      href="http://arxiv.org/abs/1312.1666">this paper.</a></p>
                </td>
              </tr>
              <tr>
                <td align="center" width="146"><a
                    href="https://code.google.com/p/24am/"><img
                      src="imgs/24am.png" width="127" height="55"></a></td>
                <td>
                  <p>Parallel Sparse PCA [<a
                      href="http://arxiv.org/abs/1212.4137">8</a> <a
href="http://jmlr.csail.mit.edu/papers/volume11/journee10a/journee10a.pdf">9</a>]
                    <a href="https://code.google.com/p/24am/">code</a>.
                    Supports multicore workstations, GPUs and clusters.
                    The cluster version was tested on terabyte matrices
                    and is scalable. Extension of <a
href="http://jmlr.csail.mit.edu/papers/volume11/journee10a/journee10a.pdf">GPower</a>.</p>
                </td>
              </tr>
              <tr>
                <td align="center"><a
                    href="http://code.google.com/p/ac-dc/"><img
                      src="imgs/ACDC.png" width="52" height="55"></a></td>
                <td>Serial [<a
                    href="http://link.springer.com/article/10.1007/s10107-012-0614-z#">1</a>
                  <a href="http://arxiv.org/abs/1304.5530">5</a>],
                  parallel [<a
                    href="http://link.springer.com/chapter/10.1007%2F978-3-642-29210-1_5">2</a>
                  <a href="http://arxiv.org/abs/1212.0873">3</a> <a
                    href="http://arxiv.org/abs/1303.2314">4</a>] and
                  distributed [<a
href="http://www.maths.ed.ac.uk/%7Eprichtar/Optimization_and_Big_Data/posters/Takac.pdf">6</a>
                  <a href="http://arxiv.org/abs/1310.2059">7</a>]
                  coordinate descent <a
                    href="http://code.google.com/p/ac-dc/">code</a> for
                  big data optimization. The parallel and distributed
                  codes can solve LASSO instances with terabyte matrices
                  and billions of features, and are scalable. </td>
              </tr>
            </tbody>
          </table>
        </div>
        <div style="clear: both;"> </div>
      </div>
      <div id="footer">
        <script src="x_footer.js"></script> </div>
    </div>
  </body>
</html>
