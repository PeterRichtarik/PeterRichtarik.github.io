@InProceedings{Richtarik35,
  title = 	 {Stochastic Dual Coordinate Ascent with Adaptive Probabilities},
  author = 	 {Dominik Csiba and Zheng Qu and Peter Richt\'{a}rik},
  booktitle = 	 {Proceedings of the 32nd International Conference on Machine Learning},
  pages = 	 {674--683},
  year = 	 {2015},
  editor = 	 {Francis Bach and David Blei},
  volume = 	 {37},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {Lille, France},
  month = 	 {07--09 Jul},
  publisher = 	 {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v37/csiba15.pdf},
  url = 	 {http://proceedings.mlr.press/v37/csiba15.html},
  abstract = 	 {This paper introduces AdaSDCA: an adaptive variant of stochastic dual coordinate ascent (SDCA) for solving the regularized empirical risk minimization problems. Our modification consists in allowing the method adaptively change the probability distribution over the dual variables throughout the iterative process. AdaSDCA achieves provably better complexity bound than SDCA with the best fixed probability distribution, known as importance sampling. However, it is of a theoretical character as it is expensive to implement. We also propose AdaSDCA+: a practical variant which in our experiments outperforms existing non-adaptive methods.}
}
