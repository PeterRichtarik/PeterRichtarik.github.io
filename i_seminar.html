<!DOCTYPE html>
<html>
  <head>
    <meta http-equiv="content-type" content="text/html; charset=UTF-8">

    <link rel="stylesheet" href="style.css">
    <title>Peter Richtarik</title>

    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-168147887-6"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'UA-168147887-6');
    </script>





  </head>
  <body>
    <div id="page">
      <div id="header_wrapper">
        <div id="header" class="main">
          <script src="table_header.js"></script> </div>
      </div>
      <ul class="menu">
        <li><a href="index.html">News</a></li>
        <li><a href="i_oldnews-2024.html">Old News</a></li>
        <li><a href="i_papers.html">Papers</a></li>
        <li><a href="i_talks.html">Talks</a></li>
        <li><a href="i_videotalks.html">Video Talks</a></li>
        <li><a href="i_events.html">Events</a></li>
        <li><a class="active" href="i_seminar.html">Seminar</a></li>
        <li><a href="i_software.html">Code</a></li>
        <li><a href="i_team.html">Team</a></li>
        <li><a href="i_apply.html">Apply</a></li>
        <li><a href="i_bio.html">Bio</a></li>
        <li><a href="i_teaching.html">Teaching</a></li>
        <li><a href="i_consulting.html">Consulting</a></li>
      </ul>
      <div id="wrapper" class="main">
        <div id="content">
          <h2>All Hands Meetings on Big Data Optimization - Semester 1,
            2018-2019 </h2>
          <strong>Venue:</strong> <a
            href="http://www.ed.ac.uk/maps?building=james-clerk-maxwell-building">Al
Khwarizmi Building</a>, KAUST, ROOM: 2107 (2nd floor)<br>
          <strong>Time:</strong> Sundays 12:00 - 13:30 (lunch provided)
          <br>
          <br>
          <table style="width: 900px;" border="1">
            <tbody>
              <tr>
                <td width="154"><strong>Date</strong></td>
                <td style="width: 169px;"><strong>Speaker</strong></td>
                <td width="591"><strong>Paper</strong></td>
              </tr>
              <tr>
                <td valign="top">December 16, 2018</td>
                <td valign="top"><br>
                </td>
                <td valign="top"><br>
                </td>
              </tr>
              <tr>
                <td valign="top">December 9, 2018</td>
                <td rowspan="1" colspan="2" valign="top">No meeting
                  (exams)</td>
              </tr>
              <tr>
                <td valign="top">December 2, 2018</td>
                <td rowspan="1" colspan="2" valign="top">No meeting
                  (NIPS)<br>
                </td>
              </tr>
              <tr>
                <td valign="top">November 25, 2018</td>
                <td valign="top"><br>
                </td>
                <td valign="top"><br>
                </td>
              </tr>
              <tr>
                <td valign="top">November 18, 2018</td>
                <td valign="top"><br>
                </td>
                <td valign="top"><br>
                </td>
              </tr>
              <tr>
                <td style="vertical-align: top;">November 11, 2018</td>
                <td style="vertical-align: top;"><br>
                </td>
                <td style="vertical-align: top;"><br>
                </td>
              </tr>
              <tr>
                <td style="vertical-align: top;">November 4, 2018</td>
                <td style="vertical-align: top;"><br>
                </td>
                <td style="vertical-align: top;"><br>
                </td>
              </tr>
              <tr>
                <td style="vertical-align: top;">October 28, 2018</td>
                <td style="vertical-align: top;"><br>
                </td>
                <td style="vertical-align: top;"><br>
                </td>
              </tr>
              <tr>
                <td style="vertical-align: top;">October 21, 2018</td>
                <td style="vertical-align: top;"><br>
                </td>
                <td style="vertical-align: top;"><br>
                </td>
              </tr>
              <tr>
                <td valign="top">October 14, 2018</td>
                <td valign="top"><br>
                </td>
                <td valign="top"><br>
                </td>
              </tr>
              <tr>
                <td>October 7, 2018</td>
                <td><br>
                </td>
                <td><br>
                </td>
              </tr>
              <tr>
                <td>September 30, 2018</td>
                <td>Dmitry Kovalev<br>
                </td>
                <td>Update on ongoing research work<br>
                </td>
              </tr>
              <tr>
                <td>September 23, 2018</td>
                <td rowspan="1" colspan="2">No meeting (Saudi National
                  Day)</td>
              </tr>
              <tr>
                <td>September 16, 2018</td>
                <td><br>
                </td>
                <td><br>
                </td>
              </tr>
              <tr>
                <td>September 9, 2018<br>
                </td>
                <td><a
                    href="https://vcc.kaust.edu.sa/Pages/Sailanbayev.aspx">Alibek









                    Sailanbayev</a></td>
                <td>Optimization of composition of functions<br>
                </td>
              </tr>
              <tr>
                <td>September 6, 2018<br>
                </td>
                <td><a href="https://samuelhorvath.github.io">Samuel
                    Horváth</a></td>
                <td>Stochastic nested variance reduction for nonconvex
                  optimization (<a
                    href="https://arxiv.org/abs/1806.07811">Zhou, Xu, Gu
                    - 6/2018</a>)<br>
                </td>
              </tr>
              <tr>
                <td>August 30, 2018<br>
                </td>
                <td> Sarah Sachs<br>
                </td>
                <td>Generalizations of Jacobian sketching (summary of
                  research work done during 6 months of internship at
                  KAUST)<br>
                </td>
              </tr>
            </tbody>
          </table>
          <br>
          <strong>Organizers:</strong> Filip Hanzely, Aritra Dutta and
          Peter Richtárik<br>
          <br>
          <br>
          <h2>All Hands Meetings on Big Data Optimization - Semester 2,
            2017-2018 </h2>
          <strong>Venue:</strong> <a
            href="http://www.ed.ac.uk/maps?building=james-clerk-maxwell-building">Al
Khwarizmi






            Building</a>, KAUST, ROOM: 2107 (2nd floor)<br>
          <strong>Time:</strong> Tuesdays 12:00 - 13:30 (lunch provided)
          <br>
          <br>
          <table style="width: 900px;" border="1">
            <tbody>
              <tr>
                <td width="154"><strong>Date</strong></td>
                <td style="width: 169px;"><strong>Speaker</strong></td>
                <td width="591"><strong>Paper</strong></td>
              </tr>
              <tr>
                <td style="vertical-align: top;">May 27, 2018<br>
                </td>
                <td style="vertical-align: top;"><a
                    href="http://maiage.jouy.inra.fr/?q=fr/bergou">El
                    Houcine Bergou</a> </td>
                <td style="vertical-align: top;">A line search algorithm
                  inspired by the adaptive cubic regularization
                  framework and complexity analysis (<a
                    href="http://www.optimization-online.org/DB_FILE/2017/06/6083.pdf">Bergou,









                    Diouane, Gratton - 5/2018</a>)<br>
                </td>
              </tr>
              <tr>
                <td style="vertical-align: top;">May 6, 2018<br>
                </td>
                <td style="vertical-align: top;"><a
                    href="https://matthias.pw">Matthias Mueller</a><br>
                </td>
                <td style="vertical-align: top;">Optimization for deep
                  learning<br>
                </td>
              </tr>
              <tr>
                <td style="vertical-align: top;">April 29, 2018</td>
                <td style="vertical-align: top;"><a
                    href="https://samuelhorvath.github.io">Samuel
                    Horváth</a></td>
                <td style="vertical-align: top;">Second order stochastic
                  optimization for machine learning in linear time (<a
                    href="http://www.jmlr.org/papers/volume18/16-491/16-491.pdf">Agarwal,









                    Bullins, Hazan - JMLR 2017</a>)<br>
                </td>
              </tr>
              <tr>
                <td style="vertical-align: top;">April 15, 2018</td>
                <td style="vertical-align: top;"><a
                    href="https://fhanzely.github.io/index.html">Filip
                    Hanzely</a></td>
                <td style="vertical-align: top;">On the convergence of
                  Adam and beyond (<a
                    href="https://openreview.net/pdf?id=ryQu7f-RZ">Reddi,









                    Kale, Kumar - ICLR 2018</a>)<br>
                </td>
              </tr>
              <tr>
                <td valign="top">April 8, 2018</td>
                <td valign="top"><a href="https://konstmish.github.io">Konstantin









                    Mishchenko</a></td>
                <td valign="top">A simple practical accelerated method
                  for finite sums (<a
href="http://papers.nips.cc/paper/6154-a-simple-practical-accelerated-method-for-finite-sums.pdf">Defazio









                    - NIPS 2016</a>)<br>
                </td>
              </tr>
              <tr>
                <td>March 25, 2018<br>
                </td>
                <td><a href="http://www.adelbibi.com">Adel Bibi</a><br>
                </td>
                <td>Analytic expressions for probabilistic moments of
                  PL-DNN with Gaussian input<br>
                </td>
              </tr>
              <tr>
                <td>March 18, 2018<br>
                </td>
                <td><a href="https://konstmish.github.io">Konstantin&nbsp;









                    Mishchenko</a> </td>
                <td>Penalty formulation for constrained optimization<br>
                </td>
              </tr>
              <tr>
                <td>March 11, 2018 </td>
                <td><a
                    href="https://vcc.kaust.edu.sa/Pages/Sailanbayev.aspx">Alibek









                    Sailanbayev</a> </td>
                <td>SignSGD: Compressed optimization for non-convex
                  problems (<a
                    href="https://arxiv.org/pdf/1802.04434.pdf">Bernstein,









                    Wang, Azizzadenesheli, Anandkumar - ICML 2018</a>)<br>
                </td>
              </tr>
              <tr>
                <td>March 4, 2018<br>
                </td>
                <td><a href="https://samuelhorvath.github.io">Samuel
                    Horváth</a><br>
                </td>
                <td>Fast incremental method for nonconvex optimization (<a
                    href="https://arxiv.org/pdf/1603.06159.pdf">Reddi,
                    Sra, Poczos, Smola - 3/2016</a>)<br>
                </td>
              </tr>
              <tr>
                <td>February 27, 2018<br>
                </td>
                <td><a href="http://maiage.jouy.inra.fr/?q=fr/bergou">El
                    Houcine Bergou<br>
                  </a></td>
                <td>Random direct search method for unconstrained
                  minimization<br>
                </td>
              </tr>
              <tr>
                <td>February 20, 2018<br>
                </td>
                <td><a href="https://fhanzely.github.io/index.html">Filip









                    Hanzely</a> </td>
                <td>The implicit bias of gradient descent on separable
                  data (<a href="https://arxiv.org/abs/1710.10345">Soudry,






                    Hoffer, Nacson, Gunasekar, Srebro - 10/2017</a>)<br>
                </td>
              </tr>
              <tr>
                <td>February 13, 2018<br>
                </td>
                <td><a href="https://www.maths.ed.ac.uk/%7Es1461357/">Nicolas









                    Loizou</a> </td>
                <td>Random inexact projection methods<br>
                </td>
              </tr>
            </tbody>
          </table>
          <br>
          <strong>Organizers:</strong> Filip Hanzely, Aritra Dutta and
          Peter Richtárik<br>
          <br>
          <br>
          <h2>All Hands Meetings on Big Data Optimization - Semester 1,
            2017-2018 </h2>
          <strong>Venue:</strong> <a
            href="http://www.ed.ac.uk/maps?building=james-clerk-maxwell-building">Al










            Khwarizmi Building</a>, KAUST, ROOM: 2107 (2nd floor)<br>
          <strong>Time:</strong> Tuesdays 12:00 - 13:30 (lunch provided)
          <br>
          <br>
          <table style="width: 900px;" border="1">
            <tbody>
              <tr>
                <td width="154"><strong>Date</strong></td>
                <td style="width: 169px;"><strong>Speaker</strong></td>
                <td width="591"><strong>Paper</strong></td>
              </tr>
              <tr>
              </tr>
              <tr>
                <td valign="top">December 5, 2017<br>
                </td>
                <td valign="top"><a href="https://konstmish.github.io">Konstantin










                    Mishchenko</a></td>
                <td valign="top"> SARAH: A novel method for machine
                  learning problems using stochastic recursive gradient
                  (<a href="https://arxiv.org/pdf/1703.00102.pdf">Nguyen,










                    Liu, Scheinberg, Takac - ICML 2017</a>)<br>
                </td>
              </tr>
              <tr>
                <td>November 28, 2017<br>
                </td>
                <td><a href="https://fhanzely.github.io/index.html">Filip










                    Hanzely</a><br>
                </td>
                <td>Relative continuity for non-Lipschitz non-smooth
                  convex optimization using stochastic (or
                  deterministic) mirror descent (<a
                    href="https://arxiv.org/abs/1710.04718">Lu - 10/2017</a>)<br>
                </td>
              </tr>
              <tr>
              </tr>
              <tr>
              </tr>
              <tr>
                <td style="vertical-align: top;">November 21, 2017<br>
                </td>
                <td style="vertical-align: top;"><a
                    href="https://perso.telecom-paristech.fr/rgower/">Robert










                    Gower</a><br>
                </td>
                <td style="vertical-align: top;">SAGA is a variant of
                  stochastic gradient: new view and new proof<br>
                </td>
              </tr>
              <tr>
                <td style="vertical-align: top;">November 14, 2017<br>
                </td>
                <td style="vertical-align: top;"><a
                    href="https://www.maths.ed.ac.uk/%7Es1461357/">Nicolas










                    Loizou</a><br>
                </td>
                <td style="vertical-align: top;">First-order adaptive
                  sample size methods to reduce complexity of empirical
                  risk minimization (<a
                    href="https://arxiv.org/abs/1709.00599">Mokhtari,
                    Ribeiro - 9/2017</a>)<br>
                </td>
              </tr>
              <tr>
                <td style="vertical-align: top;">November 7, 2017<br>
                </td>
                <td style="vertical-align: top;"><a
                    href="https://konstmish.github.io">Konstantin
                    Mishchenko</a><br>
                </td>
                <td style="vertical-align: top;">Proximal-proximal-gradient










                  method (<a href="https://arxiv.org/pdf/1708.06908.pdf">Ryu,










                    Yin - 8/2017</a>)<br>
                </td>
              </tr>
              <tr>
                <td style="vertical-align: top;">October 31, 2017</td>
                <td style="vertical-align: top;"><a
                    href="https://www.hse.ru/en/staff/nikitadoikov">Nikita










                    Doikov</a><br>
                </td>
                <td style="vertical-align: top;">Regularized Newton
                  methods for minimizing functions with Hölder
                  continuous Hessians (<a
                    href="https://epubs.siam.org/doi/abs/10.1137/16M1087801">Grapiglia,










                    Nesterov - SIOPT 2017</a>) Cubic regularization of
                  Newton method and its global performance (<a
                    href="http://lab7.ipu.ru/files/polyak/Nest_Pol-MathProg%2706.pdf">Nesterov,










                    Polyak - MAPR 2006</a>)<br>
                </td>
              </tr>
              <tr>
                <td style="vertical-align: top;">October 24, 2017</td>
                <td style="vertical-align: top;">Viktor Lukáček<br>
                </td>
                <td style="vertical-align: top;">Dykstra's algorithm
                  with Bregman projections: a convergence proof (<a
                    href="https://www.tandfonline.com/doi/abs/10.1080/02331930008844513">Bauschke,










                    Lewis - Optimization 1998</a>)<br>
                </td>
              </tr>
              <tr>
                <td valign="top">October 17, 2017 </td>
                <td valign="top"><a href="http://sstich.ch">Sebastian
                    Stich</a><br>
                </td>
                <td valign="top">Approximate steepest coordinate descent
                  (<a href="https://arxiv.org/abs/1706.08427">Stich,
                    Raj, Jaggi - ICML 2017</a>)<br>
                </td>
              </tr>
              <tr>
                <td>October 10, 2017<br>
                </td>
                <td><a
                    href="https://vcc.kaust.edu.sa/Pages/Sailanbayev.aspx">Alibek










                    Sailanbayev</a><br>
                </td>
                <td>Breaking locality accelerates block Gauss-Seidel (<a
                    href="https://arxiv.org/abs/1701.03863">Tu,
                    Venkataraman, Wilson, Gittens, Jordan, Recht - ICML
                    2017</a>)<br>
                </td>
              </tr>
              <tr>
              </tr>
              <tr>
                <td>October 3, 2017<br>
                </td>
                <td><a href="https://konstmish.github.io">Konstantin&nbsp;










                    Mishchenko</a> </td>
                <td>An asynchronous distributed prox-grad algorithm (<a
href="https://docs.google.com/viewer?a=v&amp;pid=sites&amp;srcid=ZGVmYXVsdGRvbWFpbnxhbGxoYW5kc29wdGltaXphdGlvbnxneDo1ODU0MjM5ZjZmNmViYmJh">Mishchenko,










                    Iutzeler, Malick - 2017</a>) </td>
              </tr>
              <tr>
              </tr>
              <tr>
                <td>September 26, 2017 </td>
                <td><a href="https://konstmish.github.io">Konstantin&nbsp;










                    Mishchenko</a><br>
                </td>
                <td>An asynchronous distributed prox-grad algorithm (<a
href="https://docs.google.com/viewer?a=v&amp;pid=sites&amp;srcid=ZGVmYXVsdGRvbWFpbnxhbGxoYW5kc29wdGltaXphdGlvbnxneDo1ODU0MjM5ZjZmNmViYmJh">Mishchenko,










                    Iutzeler, Malick - 2017</a>) </td>
              </tr>
              <tr>
              </tr>
              <tr>
                <td>September 19, 2017<br>
                </td>
                <td><a href="https://www.aritradutta.com">Aritra Dutta</a><br>
                </td>
                <td>Self-occlusion and disocclusion in causal video
                  object segmentation (<a
                    href="http://vision.ucla.edu/%7Eganeshs/pubs/iccv15.pdf">ICCV










                    2015</a>)<br>
                </td>
              </tr>
              <tr>
              </tr>
              <tr>
                <td>September 12, 2017<br>
                </td>
                <td><a href="https://fhanzely.github.io/index.html">Filip










                    Hanzely</a></td>
                <td>Randomized methods for relative smooth optimization
                  (<a
href="https://repository.kaust.edu.sa/bitstream/handle/10754/623944/poster_Hanzely.pdf?sequence=1">Hanzely,










                    Richtarik - 2017</a>)<br>
                </td>
              </tr>
              <tr>
              </tr>
              <tr>
                <td>August 29, 2017<br>
                </td>
                <td><a href="https://fhanzely.github.io/index.html">Filip










                    Hanzely</a><br>
                </td>
                <td>Relatively-smooth convex optimization by first-order
                  methods, and applications (<a
                    href="https://arxiv.org/abs/1610.05708">Lu, Freund
                    and Nesterov - 10/2016</a>)<br>
                </td>
              </tr>
              <tr>
              </tr>
              <tr>
                <td>August 22, 2017<br>
                </td>
                <td><a href="https://www.aritradutta.com">Aritra Dutta</a><br>
                </td>
                <td>A Batch-Incremental Video Background Estimation
                  Model using Weighted Low-Rank Approximation of
                  Matrices (<a
                    href="https://arxiv.org/pdf/1707.00281.pdf">Dutta,
                    Li and Richtárik - 7/2017</a>)<br>
                </td>
              </tr>
              <tr>
              </tr>
              <tr>
              </tr>
            </tbody>
          </table>
          <br>
          <strong>Organizers:</strong> Filip Hanzely, Aritra Dutta and
          Peter Richtárik<br>
          <br>
          <br>
          <h2> All Hands Meetings on Big Data Optimization - Semester 2,
            2016-2017 </h2>
          <strong>Venue:</strong> <a
            href="http://www.ed.ac.uk/maps?building=james-clerk-maxwell-building">James
Clerk










            Maxwell Building</a> ROOM: JCMB 5323 (5th floor)<br>
          <strong>Time:</strong> Tuesdays 12:15 - 13:30 (lunch provided)
          <br>
          <br>
          We thankfully acknowledge support from <a
            href="http://www.maths.ed.ac.uk/%7Eigordon/"> the Head of
            School of Mathematics</a> and the <a
            href="http://datascience.inf.ed.ac.uk/">Center for Doctoral
            Training in Data Science</a><br>
          <br>
          <table width="900" border="1">
            <tbody>
              <tr>
                <td width="154"><strong>Date</strong></td>
                <td width="155"><strong>Speaker</strong></td>
                <td width="591"><strong>Paper</strong></td>
              </tr>
              <tr>
              </tr>
              <tr>
                <td>March 14, 2017<br>
                </td>
                <td><a href="http://filiphanzely.com/">Filip Hanzely</a>
                </td>
                <td>Finding Approximate Local Minima for Nonconvex
                  Optimization in Linear Time (<a
                    href="https://arxiv.org/abs/1611.01146">Agarwal,
                    Allen-Zhu, Bullins, Hazan, and Ma - 11/2016</a>)<br>
                </td>
              </tr>
              <tr>
              </tr>
              <tr>
              </tr>
              <tr>
                <td valign="top">March 7, 2017<br>
                </td>
                <td valign="top"><a
                    href="http://www.macs.hw.ac.uk/%7Emp71/">Marcelo
                    Pereyra</a><br>
                </td>
                <td valign="top">Efficient Bayesian computation by
                  proximal Markov chain Monte Carlo: when Langevin meets
                  Moreau (<a href="https://arxiv.org/abs/1612.07471">Durmus,










                    Moulines and Pereyra - 12/2016</a>)<br>
                </td>
              </tr>
              <tr>
                <td> February 28, 2017<br>
                </td>
                <td><a href="http://jakubkonecny.com/">Jakub Konečný</a><br>
                </td>
                <td>QSGD: Randomized quantization for
                  communication-optimal stochastic gradient descent (<a
                    href="https://arxiv.org/abs/1610.02132">Alistarh,
                    Li, Tomioka and Vojnovic - 10/2016</a>)<br>
                </td>
              </tr>
              <tr>
              </tr>
              <tr>
                <td> February 21, 2017<br>
                </td>
                <td><a
                    href="http://www.maths.ed.ac.uk/people/show?person=479">Nicolas










                    Loizou</a><br>
                </td>
                <td>Global convergence of the Heavy-ball method for
                  convex optimization (<a
                    href="https://arxiv.org/abs/1412.7457">Ghadimi,
                    Feyzmahdavian and Johansson - 12/2014</a>)<br>
                </td>
              </tr>
              <tr>
              </tr>
              <tr>
                <td> February 14, 2017</td>
                <td><a
                    href="http://www.maths.ed.ac.uk/school-of-mathematics/people?person=506">Kostas










                    Zygalakis</a><br>
                </td>
                <td>A differential equation for modeling Nesterov's
                  accelerated gradient method: theory and insights (<a
href="https://papers.nips.cc/paper/5322-a-differential-equation-for-modeling-nesterovs-accelerated-gradient-method-theory-and-insights">Su,
Boyd










                    and Candes - NIPS 2014</a>)<br>
                </td>
              </tr>
              <tr>
              </tr>
              <tr>
                <td> February 7, 2017</td>
                <td><a href="http://personal.lse.ac.uk/veghl/">László A.
                    Végh (LSE)</a><br>
                </td>
                <td>Rescaled first-order methods for linear programming
                  (<a href="https://arxiv.org/abs/1611.06427">Dadush,
                    Végh and Zambelli 11/2016</a>)<br>
                </td>
              </tr>
              <tr>
              </tr>
              <tr>
                <td> January 31, 2017</td>
                <td><a href="http://filiphanzely.com/">Filip Hanzely</a>
                </td>
                <td>Relatively smooth convex optimization by first-order
                  methods, and applications (<a
                    href="https://arxiv.org/abs/1610.05708">Lu, Freund
                    and Nesterov - 10/2016</a>)<br>
                </td>
              </tr>
              <tr>
              </tr>
              <tr>
                <td> January 24, 2017</td>
                <td><a href="http://acse.pub.ro/person/ion-necoara/">Ion
                    Necoara (Bucharest)</a><br>
                </td>
                <td>Linear convergence of first order methods for
                  non-strongly convex optimization (<a
                    href="https://arxiv.org/abs/1504.06298">Necoara,
                    Nesterov and Glineur - 4/2015</a>)<br>
                </td>
              </tr>
              <tr>
              </tr>
              <tr>
                <td> January 17, 2017 </td>
                <td><a
                    href="https://sites.google.com/site/armineftekhari/">Armin
Eftekhari










                    (The Alan Turing Institute)</a><br>
                </td>
                <td>The alternating descent conditional gradient method
                  for sparse inverse problems (<a
                    href="https://arxiv.org/abs/1507.01562">Boyd,
                    Schiebinger and Recht - 7/2015</a>)<br>
                </td>
              </tr>
              <tr>
              </tr>
              <tr>
              </tr>
            </tbody>
          </table>
          <br>
          <strong>Organizers:</strong> <a
            href="http://www.maths.ed.ac.uk/%7Es1461357/">Nicolas Loizou</a>
          and Peter Richtárik
          <h2> </h2>
          <h2><br>
          </h2>
          <h2>All Hands Meetings on Big Data Optimization - Semester 1,
            2016-2017 </h2>
          <strong>Venue:</strong> <a
            href="http://www.ed.ac.uk/maps?building=james-clerk-maxwell-building">James
Clerk










            Maxwell Building</a> ROOM: JCMB 6207 (6th floor)<br>
          <strong>Time:</strong> Tuesdays 12:15 - 13:30 (lunch provided:
          thanks to the support of <a
            href="http://www.maths.ed.ac.uk/%7Eigordon/"> the Head of
            School</a>) <br>
          <br>
          <table width="900" border="1">
            <tbody>
              <tr>
                <td width="154"><strong>Date</strong></td>
                <td width="155"><strong>Speaker</strong></td>
                <td width="591"><strong>Paper</strong></td>
              </tr>
              <tr>
              </tr>
              <tr>
                <td valign="top">December 13, 2016<br>
                </td>
                <td valign="top"><a
                    href="http://www.doc.ic.ac.uk/%7Epp500/">Panos
                    Parpas</a><br>
                </td>
                <td valign="top">Using variational techniques to
                  understand accelerated methods (<a
                    href="https://arxiv.org/abs/1603.04245v1">Wibisono,
                    Wilson and Jordan - 3/2016</a>)<br>
                </td>
              </tr>
              <tr>
                <td valign="top">December 6, 2016<br>
                </td>
                <td valign="top">No meeting (NIPS) </td>
                <td valign="top"><br>
                </td>
              </tr>
              <tr>
                <td valign="top">November 29, 2016<br>
                </td>
                <td valign="top"><a
                    href="http://homepages.inf.ed.ac.uk/imurray2/">Iain
                    Murray</a><br>
                </td>
                <td valign="top">Fitting real-valued conditional
                  distributions. <br>
                  <br>
                  <i>Abstract:</i> Neural networks can be used for
                  regression. Given an input x, guess the output y. The
                  standard optimization task is to minimize some
                  regularized<br>
                  measure of mismatch between guesses and observed
                  training outputs.<br>
                  <br>
                  Neural networks can also express their own
                  uncertainty. For example, we<br>
                  can fit two functions, a guess m(x) and an "error-bar"
                  s(x), by maximizing the total log probability of
                  training outputs under a Gaussian model: \sum_n log
                  N(y_n; m(x_n), s(x_n)^2).<br>
                  <br>
                  Fitting functions representing Gaussian outputs by
                  stochastic steepest descent can be hard: the gradients
                  of the loss with respect to the mean depend strongly
                  on the standard deviation, making it hard to adapt
                  step-sizes.<br>
                  <br>
                  Moving beyond the Gaussian assumption, we might
                  represent p(y|x) with a mixture of Gaussians, or with
                  quantiles. For multivariate y we can use multivariate
                  Gaussians or RNADE. Gaussians are also fitted in
                  stochastic variational inference, sometimes with
                  diagonal covariances, sometimes low-rank + diagonal.<br>
                  <br>
                  We are able to optimize all these things to some
                  extent, but it's harder than conventional neural
                  networks, which hinders wide-spread adoption of the
                  methods.<br>
                  <br>
                  <i>Relevant papers </i><a
                    href="http://eprints.aston.ac.uk/373/">Mixture
                    Density Networks (MDNs)</a>, <a
                    href="http://dx.doi.org/10.1162/neco.1996.8.4.843">Multivariate










                    MDN</a>, <a
                    href="http://homepages.inf.ed.ac.uk/imurray2/pub/15tts_rnade/">RNADE</a>,
                  <a href="http://arxiv.org/abs/1605.06376">Bayesian MDN</a>,
                  <a
href="http://papers.nips.cc/paper/5812-matrix-manifold-optimization-for-gaussian-mixtures">matrix
manifold










                    optimization for Gaussian mixtures</a><br>
                </td>
              </tr>
              <tr>
                <td>November 22, 2016<br>
                </td>
                <td><a href="http://www.maths.ed.ac.uk/%7Elszpruch/">Lukasz










                    Szpruch</a> </td>
                <td>An analytical framework for a consensus-based global
                  optimization method (<a
                    href="https://arxiv.org/abs/1602.00220">Carrillo,
                    Choi, Totzek and Tse - 1/2016</a>) </td>
              </tr>
              <tr>
              </tr>
              <tr>
              </tr>
              <tr>
                <td valign="top">November 15, 2016<br>
                </td>
                <td valign="top"><a href="http://dominikcsiba.com">Dominik










                    Csiba</a> </td>
                <td valign="top">Stochastic Optimization with Variance
                  Reduction for Infinite Datasets with Finite-Sum
                  Structure (<a href="https://arxiv.org/abs/1610.00970">Bietti









                    and Mairal - 10/2016</a>)<br>
                </td>
              </tr>
              <tr>
                <td> November 8, 2016<br>
                </td>
                <td><a href="http://www.maths.ed.ac.uk/%7Eateckent/">Aretha










                    Teckentrup</a><br>
                </td>
                <td>Large-scale Gaussian process regression via doubly
                  stochastic gradient descent (<a
                    href="www.cc.gatech.edu/%7Ebboots3/files/gp_dsgd_ICML_WS_15.pdf">Yan,
Xie,










                    Song and Boots - 2015</a>)<br>
                </td>
              </tr>
              <tr>
              </tr>
              <tr>
                <td> November 1, 2016<br>
                </td>
                <td><a href="http://filiphanzely.com/">Filip Hanzely</a><br>
                </td>
                <td>Variance reduction for faster non-convex
                  optimization (<a
                    href="https://arxiv.org/abs/1603.05643">Allen-Zhu
                    and Hazan - 3/2016</a>)<br>
                </td>
              </tr>
              <tr>
              </tr>
              <tr>
                <td> October 25, 2016</td>
                <td> <a href="http://dominikcsiba.com">Dominik Csiba</a>
                </td>
                <td>Linear coupling: an ultimate unification of gradient
                  and mirror descent (<a
                    href="https://arxiv.org/abs/1407.1537">Allen-Zhu and
                    Orecchia - 1/2015</a>)<br>
                </td>
              </tr>
              <tr>
              </tr>
              <tr>
                <td> October 18, 2016</td>
                <td> <a href="http://jakubkonecny.com/">Jakub Konečný</a>
                </td>
                <td>Train faster, generalize better: Stability of
                  stochastic gradient descent (<a
                    href="https://arxiv.org/abs/1509.01240">Hardt, Rech
                    and Singer - 7/2016</a>)<br>
                </td>
              </tr>
              <tr>
              </tr>
              <tr>
                <td> October 11, 2016</td>
                <td><a
                    href="http://www.maths.ed.ac.uk/people/show?person=479">Nicolas










                    Loizou</a> </td>
                <td>Convergence rates for greedy Kaczmarz algorithms,
                  and faster randomized Kaczmarz rules using the
                  orthogonality graph (<a
                    href="http://auai.org/uai2016/proceedings/papers/77.pdf">Nutini,
Sepehry,










                    Laradji, Schmidt, Koepke, Virani - UAI 2016</a>) <a
                    href="auai.org/uai2016/proceedings/supp/77_supp.pdf">supplementary










                    material</a> <a
href="https://www.cs.ubc.ca/%7Eschmidtm/Documents/2016_UAI_greedyKaczmarz.pdf">poster</a><br>
                </td>
              </tr>
              <tr>
              </tr>
              <tr>
                <td> October 4, 2016</td>
                <td><a href="http://jakubkonecny.com/">Jakub Konečný</a>
                </td>
                <td>Differentially private empirical risk minimization (<a
href="http://www.jmlr.org/papers/volume12/chaudhuri11a/chaudhuri11a.pdf">Chaudhuri,
Monteleoni,










                    Sarwate - JMLR 2011</a>)<br>
                </td>
              </tr>
              <tr>
              </tr>
              <tr>
                <td> September 27, 2016 </td>
                <td><a href="http://dominikcsiba.com">Dominik Csiba</a>
                </td>
                <td>Online ad allocation via online optimization (<a
                    href="https://arxiv.org/pdf/1602.05394.pdf">Jenatton,










                    Huang, Csiba and Archambeau - 6/2016</a>) </td>
              </tr>
              <tr>
              </tr>
              <tr>
              </tr>
            </tbody>
          </table>
          <br>
          <strong>Organizers:</strong> <a
            href="http://dominikcsiba.com">Dominik Csiba</a> and Peter
          Richtárik
          <h2> </h2>
          <h2><br>
          </h2>
          <h2>All Hands Meetings on Big Data Optimization - Semester 2,
            2015-2016 </h2>
          <strong>Venue:</strong> <a
            href="http://www.ed.ac.uk/maps?building=james-clerk-maxwell-building">James
Clerk










            Maxwell Building</a> ROOM: JCMB 4312 (4th floor)<br>
          <strong>Time:</strong> Tuesdays 12:15 - 13:30 (lunch provided:
          thanks to the support of <a
            href="http://www.maths.ed.ac.uk/%7Eigordon/"> the Head of
            School</a>) <br>
          <br>
          <table width="900" border="1">
            <tbody>
              <tr>
                <td width="154"><strong>Date</strong></td>
                <td width="155"><strong>Speaker</strong></td>
                <td width="591"><strong>Paper</strong></td>
              </tr>
              <tr>
              </tr>
              <tr>
                <td valign="top">May 3, 2016<br>
                </td>
                <td valign="top"><a
                    href="http://www-syscom.univ-mlv.fr/%7Epesquet/index.htm">JC










                    Pesquet (Paris)</a><br>
                </td>
                <td valign="top">A stochastic majorize-minimize subspace
                  algorithm with application to filter identification (<a
                    href="http://arxiv.org/abs/1512.08722">Chouzenoux
                    and Pesquet - 12/2015</a>)<br>
                </td>
              </tr>
              <tr>
                <td valign="top">April 26, 2016<br>
                </td>
                <td valign="top"><a
                    href="http://www.maths.ed.ac.uk/%7Es1065527/">Robert
                    M Gower</a> </td>
                <td valign="top">Open-ended research discussion on the
                  topic: "Newton-type methods for solving the empirical
                  risk minimization problem"<br>
                </td>
              </tr>
              <tr>
                <td valign="top">April 19, 2016<br>
                </td>
                <td valign="top"><a
                    href="http://math.mit.edu/directory/profile.php?pid=1640">Haihao










                    Lu (MIT)</a><br>
                </td>
                <td valign="top">Norm-free methods<br>
                </td>
              </tr>
              <tr>
                <td valign="top">April 12, 2016<br>
                </td>
                <td valign="top"><a
                    href="http://www.uclouvain.be/sebastian.stich">Sebastian
Stich










                    (CORE)</a><br>
                </td>
                <td valign="top">A simple, combinatorial algorithm for
                  solving SDD systems in nearly-linear time (<a
                    href="http://arxiv.org/abs/1301.6628">Kelner,
                    Orecchia, Sidford, Allen-Zhu - 1/2013</a>)<br>
                </td>
              </tr>
              <tr>
                <td valign="top">April 5, 2016<br>
                </td>
                <td colspan="2" valign="top">No meeting (Easter)<br>
                </td>
              </tr>
              <tr>
                <td>March 29, 2016<br>
                </td>
                <td colspan="2">No meeting (Easter) </td>
              </tr>
              <tr>
              </tr>
              <tr>
              </tr>
              <tr>
                <td valign="top">March 22, 2016<br>
                </td>
                <td valign="top"><a
                    href="http://www.maths.ed.ac.uk/people/show?person=479">Nicolas










                    Loizou</a> </td>
                <td valign="top">Second order stochastic optimization in
                  linear time (<a href="http://arxiv.org/abs/1602.03943">Agarwal,










                    Bullins and Hazan - 2/2016</a>)<br>
                </td>
              </tr>
              <tr>
                <td> March 15, 2016<br>
                </td>
                <td><a href="http://www.maths.ed.ac.uk/%7Es1065527/">Robert










                    M Gower</a> </td>
                <td>Sub-sampled Newton methods I: globally convergent
                  algorithms (<a href="http://arxiv.org/abs/1601.04737">Roosta-Khorasani










                    and Mahoney - 1/2016</a>)<br>
                </td>
              </tr>
              <tr>
              </tr>
              <tr>
                <td> March 8, 2016<br>
                </td>
                <td colspan="2">No meeting (I am in <a
                    href="https://www.mfo.de/occasion/1610/www_view">Oberwolfach</a>...)<br>
                </td>
              </tr>
              <tr>
              </tr>
              <tr>
                <td> March 1, 2016</td>
                <td><a href="http://dominikcsiba.com">Dominik Csiba</a>
                </td>
                <td>Local smoothness in variance-reduced optimization (<a
href="https://papers.nips.cc/paper/5913-local-smoothness-in-variance-reduced-optimization.pdf">Vainsencher,
Liu










                    and Zhang - NIPS 2015</a> )<br>
                </td>
              </tr>
              <tr>
              </tr>
              <tr>
                <td> February 23, 2016</td>
                <td><a
                    href="https://www.inf.ed.ac.uk/people/staff/Jaroslav_Fowkes.html">Jaroslav










                    Fowkes</a><br>
                </td>
                <td>Submodular function maximization (based on a <a
                    href="https://las.inf.ethz.ch/files/krause12survey.pdf">survey










                    of Krause and Golovin 2012</a>)<br>
                </td>
              </tr>
              <tr>
              </tr>
              <tr>
                <td> February 16, 2016</td>
                <td><a href="http://jakubkonecny.com/">Jakub Konečný</a>
                </td>
                <td>Taming the wild: a unified analysis of
                  Hogwild!-style algorithms (<a
href="http://papers.nips.cc/paper/5717-taming-the-wild-a-unified-analysis-of-hogwild-style-algorithms.pdf">De
Sa,










                    Zhang, Olukotun, Re - NIPS 2015</a>)<br>
                </td>
              </tr>
              <tr>
              </tr>
              <tr>
                <td> February 9 2016</td>
                <td colspan="2">No meeting (<a
                    href="http://dominikcsiba.com">Dominik</a>, <a
                    href="http://jakubkonecny.com/">Jakub</a>, <a
                    href="http://www.maths.ed.ac.uk/%7Es1065527/">Robert</a>
                  and I will be in <a
                    href="http://www.di.ens.fr/%7Easpremon/Houches/index.html">Les










                    Houches</a>) <br>
                </td>
              </tr>
              <tr>
              </tr>
              <tr>
                <td> February 2, 2016 </td>
                <td><a
                    href="http://www.maths.ed.ac.uk/people/show?person=479">Nicolas










                    Loizou</a> </td>
                <td> Randomized gossip algorithms (<a
                    href="http://www.arpitaghosh.com/papers/gossip.pdf">Boyd,










                    Ghosh, Prabhakar and Shah - IEEE Transactions on
                    Information Theory 2006</a> and <a
                    href="http://users.ece.utexas.edu/%7Edimakis/Gossip_Survey.pdf">Dimakis,
Kar,










                    Moura, Rabbat and Scaglione - Proceedings of the
                    IEEE</a>)<br>
                </td>
              </tr>
              <tr>
              </tr>
              <tr>
                <td> January 26, 2016 </td>
                <td> <a href="http://jakubkonecny.com/">Jakub Konečný</a>
                </td>
                <td> On Variance Reduction in Stochastic Gradient
                  Descent and its Asynchronous Variants (<a
href="https://papers.nips.cc/paper/5821-on-variance-reduction-in-stochastic-gradient-descent-and-its-asynchronous-variants.pdf">Reddi,
Hefny,










                    Sra, Poczos and Smola - NIPS 2015</a>)</td>
              </tr>
              <tr>
              </tr>
            </tbody>
          </table>
          <br>
          <p><strong>Organizers:</strong> <a
              href="http://jakubkonecny.com/">Jakub Konečný</a> and
            Peter Richtárik<br>
            <br>
          </p>
          <h2>All Hands Meetings on Big Data Optimization - Semester 1,
            2015-2016 </h2>
          <strong>Venue:</strong> <a
            href="http://www.ed.ac.uk/maps?building=james-clerk-maxwell-building">James
Clerk










            Maxwell Building</a> ROOM: JCMB 6311 (6th floor)<br>
          <strong>Time:</strong> 12:15 - 13:15 (lunch provided: thanks
          to the support of <a
            href="http://www.maths.ed.ac.uk/%7Eigordon/"> the Head of
            School</a>) <br>
          <br>
          <table width="900" border="1">
            <tbody>
              <tr>
                <td width="154"><strong>Date</strong></td>
                <td width="155"><strong>Speaker</strong></td>
                <td width="591"><strong>Paper</strong></td>
              </tr>
              <tr>
              </tr>
              <tr>
                <td> November 24, 2015</td>
                <td><a
href="http://www.research.ed.ac.uk/portal/en/persons/nick-polydorides%28e48b7d48-c4df-49cf-bc78-a3e328c32131%29.html">Nick










                    Polydorides</a></td>
                <td> A quasi Monte Carlo method for large-scale inverse
                  problems (<a
href="http://www.mit.edu/%7Edimitrib/polydorides_wang_bertsekas_final.pdf">Polydorides,
Wang










                    &amp; Bertsekas - 2012</a>) more resources: [<a
                    href="http://www.mit.edu/%7Edimitrib/regression.pdf">regression</a>,
                  <a href="http://www.mit.edu/%7Edimitrib/inverse.pdf">inverse</a>,
                  <a
                    href="http://web.mit.edu/dimitrib/www/dpchapter.pdf">DP










                    chapter</a>]<br>
                </td>
              </tr>
              <tr>
              </tr>
              <tr>
              </tr>
              <tr>
                <td valign="top">November 17, 2015</td>
                <td valign="top"><a
                    href="http://www.maths.ed.ac.uk/people/show?person=461">Ran










                    Zhang </a></td>
                <td valign="top">Path-following methods (<a
                    href="docs/Wright-Ch5-Path-Following-Algorithms.pdf">Chapter










                    5</a> of Wright's <a
href="http://www.amazon.co.uk/Primal-Dual-Interior-Point-Methods-Stephen-Wright/dp/089871382X">"Primal-dual
interior-point










                    methods"</a> book)</td>
              </tr>
              <tr>
                <td> November 10, 2015</td>
                <td><a href="http://jakubkonecny.com/">Jakub Konečný</a></td>
                <td> Why random reshuffling beats stochastic gradient
                  descent (<a href="http://arxiv.org/abs/1510.08560">Gurbuzbalaban,










                    Ozdaglar and Parrilo - 10/2015)</a> </td>
              </tr>
              <tr>
              </tr>
              <tr>
                <td> November 3, 2015</td>
                <td><a
                    href="http://www.maths.ed.ac.uk/people/show?person=479">Nicolas










                    Loizou</a><br>
                </td>
                <td> Stochastic gradient descent, weighted sampling and
                  the randomized Kaczmarz algorithm (<a
                    href="http://arxiv.org/abs/1310.5715">Needell,
                    Srebro and Ward - 10/2013</a>)</td>
              </tr>
              <tr>
              </tr>
              <tr>
                <td> October 27, 2015</td>
                <td><a href="http://dominikcsiba.com">Dominik Csiba</a><br>
                </td>
                <td> A universal catalyst for first-order optimization (<a
                    href="http://arxiv.org/abs/1506.02186">Lin, Mairal
                    &amp; Harchaoui - 6/2015</a>)<br>
                </td>
              </tr>
              <tr>
              </tr>
              <tr>
                <td> October 20, 2015</td>
                <td>No meeting<br>
                </td>
                <td> <br>
                </td>
              </tr>
              <tr>
              </tr>
              <tr>
                <td> October 13, 2015</td>
                <td><a href="http://www.maths.ed.ac.uk/%7Es1065527/">Robert










                    M Gower</a></td>
                <td>Convergence rates of sub-sampled Newton methods (<a
                    href="http://arxiv.org/abs/1508.02810">Erdogdu &amp;
                    Montanari - 8/2015</a>) <br>
                </td>
              </tr>
              <tr>
              </tr>
              <tr>
                <td> October 6, 2015</td>
                <td><a href="http://www.maths.ed.ac.uk/%7Es1065527/">Robert










                    M Gower</a><br>
                </td>
                <td> Newton sketch (<a
                    href="http://arxiv.org/abs/1505.02250">Pilanci &amp;
                    Wainwright - 5/2015</a>)<br>
                </td>
              </tr>
              <tr>
              </tr>
              <tr>
                <td> September 29, 2015 </td>
                <td><a href="http://dominikcsiba.com">Dominik Csiba</a><br>
                </td>
                <td> Beyond convexity: stochastic quasi-convex
                  optimization (<a
                    href="http://arxiv.org/abs/1507.02030">Hazan, Levy
                    and S-Shwartz - 7/2015</a>) </td>
              </tr>
              <tr>
              </tr>
              <tr>
                <td> September 22, 2015 </td>
                <td> <a href="http://jakubkonecny.com/">Jakub Konečný</a>
                </td>
                <td> Communication Complexity of Distributed Convex
                  Learning and Optimization (<a
                    href="http://www.arxiv.org/pdf/1506.01900.pdf">Arjevani
and










                    Shamir - 6/2015</a>)</td>
              </tr>
              <tr>
              </tr>
            </tbody>
          </table>
          <br>
          <p><strong>Organizers:</strong> <a
              href="http://jakubkonecny.com/">Jakub Konečný</a> and
            Peter Richtárik</p>
          <br>
          <h2> All Hands Meetings on Big Data Optimization - Semester 2,
            2014-2015 </h2>
          <strong>Venue:</strong> <a
            href="http://www.ed.ac.uk/maps?building=james-clerk-maxwell-building">James
Clerk










            Maxwell Building</a> ROOM: JCMB 4312 (4th floor)<br>
          <strong>Time:</strong> 12:15 - 13:15 (lunch provided: thanks
          to the support of <a
            href="http://www.maths.ed.ac.uk/%7Eigordon/"> the Head of
            School</a>) <br>
          <br>
          <table width="900" border="1">
            <tbody>
              <tr>
                <td width="154"><strong>Date</strong></td>
                <td width="155"><strong>Speaker</strong></td>
                <td width="591"><strong>Paper</strong></td>
              </tr>
              <tr>
                <td> May 19, 2015</td>
                <td> <a
                    href="http://www.maths.ed.ac.uk/people/show?person=344">Ian
Wallace










                  </a></td>
                <td> HELM: Holomorphic Embedding Load flow Method
                  (papers: <a
href="http://ieeexplore.ieee.org/xpl/articleDetails.jsp?reload=true&amp;&amp;arnumber=6344759">1</a>
                  and <a
href="http://ieeexplore.ieee.org/xpl/articleDetails.jsp?arnumber=6666940">2</a>
                  )</td>
              </tr>
              <tr>
                <td> May 12, 2015</td>
                <td> <a href="http://www.maths.ed.ac.uk/%7Eagr/">Andreas










                    Grothey</a> </td>
                <td> Contingency generation for AC optimal power flow (<a
href="http://www.maths.ed.ac.uk/%7Eagr/dcopf_oops.pdf">Chiang and
                    Grothey - 2012</a> <a
                    href="http://www.optimization-online.org/DB_HTML/2012/08/3583.html">[Optimization










                    Online]</a>)</td>
              </tr>
              <tr>
                <td> May 5, 2015</td>
                <td colspan="2">No meeting due to <a
href="http://www.maths.ed.ac.uk/%7Eprichtar/Optimization_and_Big_Data_2015/">Optimization
and










                    Big Data 2015</a></td>
              </tr>
              <tr>
                <td> April 28, 2015</td>
                <td> <a href="http://www.maths.ed.ac.uk/%7Ezqu/">Zheng
                    Qu</a></td>
                <td> On lower and upper bounds for smooth and strongly
                  convex optimization problems (<a
                    href="http://arxiv.org/abs/1503.06833">Arjevani,
                    Shalev-Shwartz and Shamir - 3/2015</a>)</td>
              </tr>
              <tr>
                <td> April 21, 2015</td>
                <td><a
                    href="https://www.eng.ed.ac.uk/about/people/dr-alessandro-perelli">Alessandro










                    Perelli</a></td>
                <td> Combining ordered subsets and momentum for
                  accelerated X-ray CT image reconstruction (<a
                    href="bdo_seminar/fessler.pdf">Donghwan, Ramani and
                    Fessler - 1/2015</a>, <a
                    href="http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6882248">IEEE










                    link</a>)</td>
              </tr>
              <tr>
                <td> April 14, 2015</td>
                <td> <a href="http://www.maths.ed.ac.uk/%7Es1065527/">Robert










                    Gower</a> </td>
                <td> Research discussion </td>
              </tr>
              <tr>
                <td> April 7, 2015</td>
                <td colspan="2">No meeting due to Easter Break</td>
              </tr>
              <tr>
                <td> March 31, 2015</td>
                <td><a href="http://dominikcsiba.com">Dominik Csiba</a></td>
                <td> Stochastic Dual Coordinate Ascent (SDCA): A
                  Dual-Free Analysis (<a
                    href="http://arxiv.org/abs/1502.06177">Shai
                    Shalev-Shwartz - 2/2015</a>)</td>
              </tr>
              <tr>
                <td> March 24, 2015</td>
                <td><a href="http://jakubkonecny.com/">Jakub Konečný</a></td>
                <td> Greedy coordinate descent vs randomized coordinate
                  descent</td>
              </tr>
              <tr>
                <td> March 17, 2015</td>
                <td><a
                    href="https://sites.google.com/site/tommayoresearch/">Tom










                    Mayo</a> and <a
                    href="http://homepages.inf.ed.ac.uk/gsanguin/">Guido
                    Sanguinetti</a></td>
                <td> Challenges for predictive modelling in
                  high-throughput biology (papers: <a
                    href="http://www.pnas.org/content/111/37/13367.abstract">[1]</a>
                  and <a
                    href="http://www.nature.com/nrg/journal/v10/n10/full/nrg2641.html">[2]</a>)
                </td>
              </tr>
              <tr>
                <td> March 10, 2015</td>
                <td> <a href="http://www.maths.ed.ac.uk/%7Ezqu/">Zheng
                    Qu</a></td>
                <td> Complexity bounds for primal-dual methods
                  minimizing the model of objective function (<a
href="http://www.uclouvain.be/cps/ucl/doc/core/documents/coredp2015_3web.pdf">Nesterov
-










                    2/2015</a>)</td>
              </tr>
              <tr>
                <td> March 3, 2015</td>
                <td> <a href="http://www.maths.ed.ac.uk/%7Ekfount/">Kimon










                    Fountoulakis</a></td>
                <td> Randomized numerical linear algebra meets big data
                  optimization (<a
                    href="http://arxiv.org/abs/1502.03571">Yang, Chow,
                    Re and Mahoney - 2/2015</a> and <a
                    href="http://arxiv.org/abs/1502.03032">Yang, Meng
                    and Mahoney - 2/2015</a>) </td>
              </tr>
              <tr>
                <td> February 24, 2015</td>
                <td> <a href="http://www.maths.ed.ac.uk/%7Es1065527/">Robert










                    M. Gower</a></td>
                <td> <a href="http://arxiv.org/abs/1412.8045">Action
                    constrained quasi-Newton methods</a> (Gower and
                  Gondzio - 12/2014) </td>
              </tr>
              <tr>
                <td> February 17, 2015</td>
                <td colspan="2">no meeting due to Innovative Learning
                  Week</td>
              </tr>
              <tr>
                <td> February 10, 2015</td>
                <td><a href="http://homepages.inf.ed.ac.uk/ckiw/">Chris
                    Williams</a></td>
                <td> Linear dynamical systems applied to condition
                  monitoring (papers <a
                    href="http://homepages.inf.ed.ac.uk/ckiw/postscript/uai2014.pdf">[1]</a>
                  and <a
                    href="http://homepages.inf.ed.ac.uk/ckiw/postscript/tpami08.pdf">[2]</a>).











                  <br>
                  <br>
                  <em>Abstract:</em> We develop a Hierarchical Switching
                  Linear Dynamical System (HSLDS) for the detection of
                  sepsis in neonates in an intensive care unit. The
                  Factorial Switching LDS (FSLDS) of Quinn et al. (2009)
                  is able to describe the observed vital signs data in
                  terms of a number of discrete factors, which have
                  either physiological or artifactual origin. We
                  demonstrate that by adding a higher-level discrete
                  variable with semantics sepsis/non-sepsis we can
                  detect changes in the physiological factors that
                  signal the presence of sepsis. We demonstrate that the
                  performance of our model for the detection of sepsis
                  is not statistically different from the
                  auto-regressive HMM of Stanculescu et al. (2013),
                  despite the fact that their model is given "ground
                  truth" annotations of the physiological factors, while
                  our HSLDS must infer them from the raw vital signs
                  data. Joint work with Ioan Stanculescu and Yvonne
                  Freer. </td>
              </tr>
              <tr>
                <td> February 3, 2015</td>
                <td><a href="http://jakubkonecny.com/">Jakub Konečný</a></td>
                <td> <a href="http://arxiv.org/abs/1312.7853">Communication
efficient










                    distributed optimization using an approximate
                    Newton-type method</a> (Shamir, Srebro and Zhang -
                  12/2013) </td>
              </tr>
              <tr>
                <td> January 27, 2015</td>
                <td><a href="http://www.maths.ed.ac.uk/%7Ezqu/">Zheng Qu</a></td>
                <td> <a href="http://arxiv.org/abs/1410.0723">A lower
                    bound for the optimization of finite sums</a>
                  (Agarwal and Bottou - 10/2014)</td>
              </tr>
              <tr>
                <td> January 20, 2015</td>
                <td><a href="http://www.iliasdiakonikolas.org/">Ilias
                    Diakonikolas</a></td>
                <td> Algorithms in Statistics (papers: long version <a
href="http://www.iliasdiakonikolas.org/papers/piecewise-poly-learning.pdf">[1]











                  </a> and short version <a
                    href="http://dl.acm.org/citation.cfm?id=2591848">[2]</a>)
                  <br>
                  <br>
                  <em>Blurb:</em> A broad class of big data – such as
                  those collected from financial transactions, seismic
                  measurements, neurobiological measurements, sensor
                  nets, or network traffic records – is best modeled as
                  samples from a probability distribution over a very
                  large domain. One of the most basic statistical
                  inference tasks in this setting is this: learn the
                  underlying distribution that generated the data. </td>
              </tr>
            </tbody>
          </table>
          <br>
          <p><strong>Organizers:</strong> <a
              href="http://jakubkonecny.com/">Jakub Konečný</a>, <a
              href="http://www.maths.ed.ac.uk/%7Ezqu/">Zheng Qu </a>
            and Peter Richtárik</p>
          <br>
          <h2> All Hands Meetings on Big Data Optimization - Semester 1,
            2014-2015 </h2>
          <strong>Venue:</strong> <a
            href="http://www.ed.ac.uk/maps?building=james-clerk-maxwell-building">James
Clerk










            Maxwell Building</a> ROOM: 6311 (6th floor)<br>
          <strong>Time:</strong> Tuesdays, 12:15 - 13:15 (lunch
          provided: thanks to <a href="http://www.nais.org.uk/">NAIS</a>)
          <br>
          <br>
          <table width="764" border="1">
            <tbody>
              <tr>
                <td width="154"><strong>Date</strong></td>
                <td width="155"><strong>Speaker</strong></td>
                <td width="433"><strong>Paper</strong></td>
              </tr>
              <tr>
                <td> December 2, 2014 </td>
                <td> <a href="http://homepages.inf.ed.ac.uk/csutton/">Charles










                    Sutton</a> </td>
                <td> Optimization in Modern Machine Learning: Four
                  Vignettes (Exploratory data analysis: Mining
                  transaction data, Unsupervised learning in neural
                  networks, Signal disaggregation: Understanding
                  household energy usage, Sampling from high dimensional
                  distributions using continuous relaxations) (papers: <a
href="http://homepages.inf.ed.ac.uk/csutton/publications/zhang12continuous.pdf">[1]</a>
                  <a href="http://arxiv.org/abs/1406.3269"> [2] </a> <a
href="http://homepages.inf.ed.ac.uk/csutton/publications/afhmmsac.pdf">[3]











                  </a>) </td>
              </tr>
              <tr>
                <td> November 25, 2014 </td>
                <td> <a href="http://dominikcsiba.com">Dominik Csiba</a>
                </td>
                <td> Iterative Hessian sketch: fast and accurate
                  solution approximation for constrained least-squares
                  (based on <a
                    href="http://arxiv.org/pdf/1411.0347v1.pdf">Pilanci
                    and Wainwright</a> - 11/2014) </td>
              </tr>
              <tr>
                <td> November 18, 2014 </td>
                <td> <a
                    href="http://www.maths.ed.ac.uk/people/show?person=405">Xavier










                    Cabezas</a> </td>
                <td> Cycle bases in network synchronization problems
                  (based on [<a
href="http://www.jstor.org/stable/pdfplus/168720.pdf?&amp;acceptTC=true&amp;jpdConfirm=true">1</a>,
                  <a
href="http://ac.els-cdn.com/S0166218X06003052/1-s2.0-S0166218X06003052-main.pdf?_tid=270858e6-69c9-11e4-b26f-00000aab0f02&amp;acdnat=1415727519_8f397054cb2495c86968d0baa5f46576">2</a>,
                  <a
href="http://ac.els-cdn.com/S1574013709000483/1-s2.0-S1574013709000483-main.pdf?_tid=674385e2-69c5-11e4-a49b-00000aacb361&amp;acdnat=1415725909_d383c187e99751272df9d3280aee8672">3</a>])











                </td>
              </tr>
              <tr>
                <td> November 11, 2014 </td>
                <td> <a href="http://www.maths.ed.ac.uk/%7Ezqu/">Zheng
                    Qu</a> </td>
                <td> <a href="http://arxiv.org/pdf/1409.2617v3.pdf">Large-scale
randomized-coordinate










                    descent methods with non-separable linear
                    constraints </a> (Reddy, Hefny, Downey, Dubey and
                  Sra - 10/2014) </td>
              </tr>
              <tr>
                <td> November 4, 2014 </td>
                <td> <a href="http://people.ufpr.br/%7Eademir.ribeiro/">Ademir










                    Ribeiro</a> </td>
                <td> Towards a direct search method with adaptive
                  directions/geometry (Ademir will describe some
                  challenges of his ongoing research in the area; paper
                  to read: <a href="http://arxiv.org/abs/1410.0390">Konecny









                    and Richtarik - 09/2014</a>) </td>
              </tr>
              <tr>
                <td>October 28, 2014</td>
                <td> <a href="http://homepages.inf.ed.ac.uk/amos/">
                    Amos Storkey </a> </td>
                <td> Machine learning markets (<a
                    href="allhands20141028.html">abstract</a>)</td>
              </tr>
              <tr>
                <td>October 21, 2014</td>
                <td><a href="http://dominikcsiba.com">Dominik Csiba</a></td>
                <td><a href="http://arxiv.org/abs/1409.2848"> A
                    stochastic PCA algorithm with an exponential
                    convergence rate</a> (Shamir - 09/2014)</td>
              </tr>
              <tr>
                <td>October 14, 2014</td>
                <td><a href="http://jakubkonecny.com/">Jakub Konecny</a></td>
                <td>Parallelism in optimization (this is a brainstorming
                  session about the limits of paralleism in optimization
                  and is not based on any papers)</td>
              </tr>
              <tr>
                <td>October 7, 2014</td>
                <td><a href="http://www.maths.ed.ac.uk/%7Es1065527/">Robert










                    Gower</a></td>
                <td><a href="http://arxiv.org/pdf/1401.7020v1.pdf"> A
                    stochastic quasi-Newton method for large-scale
                    optimization </a> (Byrd, Hansen, Nocedal and Singer
                  - 2014)</td>
              </tr>
              <tr>
                <td>September 30, 2014</td>
                <td><a href="http://jakubkonecny.com/">Jakub Konecny</a></td>
                <td>Trade-offs of large scale learning (papers: <a
href="http://www.lamsade.dauphine.fr/%7Elitwin/cours98/Doc-cours-clouds/mmdss-2008.pdf">1
                    - Bottou and Bousquet</a>, <a
href="http://papers.nips.cc/paper/3323-the-tradeoffs-of-large-scale-learning.pdf">2
                    - Bottou and Bousquet</a>, <a
                    href="http://leon.bottou.org/publications/pdf/compstat-2010.pdf">3
                    - Bottou</a>)</td>
              </tr>
              <tr>
                <td>September 23, 2014</td>
                <td><a href="http://www.cmapx.polytechnique.fr/%7Equ/">Zheng










                    Qu</a></td>
                <td><a href="http://arxiv.org/abs/1407.0202">SAGA: A
                    fast incremental gradient method with support for
                    non-strongly convex composite objectives</a>
                  (Defazio, Bach and Lacoste-Julien - 2014)</td>
              </tr>
              <tr>
                <td>September 16, 2014</td>
                <td><a href="http://www.maths.ed.ac.uk/%7Ekfount/">Kimon
                    Fountoulakis</a></td>
                <td><a
                    href="http://www.maths.ed.ac.uk/ERGO/pubs/ERGO-14-010.html">Robust
block










                    coordinate descent</a> (Fountoulakis and Tappenden -
                  2014) </td>
              </tr>
            </tbody>
          </table>
          <br>
          <p><strong>Organizers:</strong> <a
              href="http://jakubkonecny.com/">Jakub Konečný</a>, <a
              href="http://www.maths.ed.ac.uk/%7Ezqu/">Zheng Qu </a>
            and Peter Richtárik</p>
          <br>
          <h2> All Hands Meetings on Big Data Optimization - Semester 2,
            2013-2014 </h2>
          <strong>Venue:</strong> <a
            href="http://www.ed.ac.uk/maps?building=james-clerk-maxwell-building">James
Clerk










            Maxwell Building</a> NEW ROOM: 4312 (4th floor)<br>
          <strong>Time:</strong> Tuesdays, 12:15 - 13:15 (refreshments
          provided: thanks to <a href="http://www.nais.org.uk/">NAIS</a>)
          <br>
          <br>
          <table width="764" border="1">
            <tbody>
              <tr>
                <td width="154"><strong>Date</strong></td>
                <td width="155"><strong>Speaker</strong></td>
                <td width="433"><strong>Paper</strong></td>
              </tr>
              <tr>
                <td>June 17, 2014</td>
                <td>Mojmír Mutný</td>
                <td><a
                    href="http://jmlr.org/proceedings/papers/v28/jaggi13-supp.pdf">Revisiting
Frank-Wolfe:










                    Projection-Free Sparse Convex Optimization</a>
                  (Martin Jaggi - ICML 2013)</td>
              </tr>
              <tr>
                <td>June 10, 2014</td>
                <td colspan="2">no meeting (due to <a
href="http://www.kcl.ac.uk/nms/depts/mathematics/events/eventsrecords/londonoptimizationworkshop.aspx">this










                    event</a>)</td>
              </tr>
              <tr>
                <td>June 3, 2014</td>
                <td><a href="http://www.maths.ed.ac.uk/%7Elszpruch/">Lukas










                    Szpruch</a></td>
                <td><a href="http://arxiv.org/pdf/1212.1377v1.pdf">Multilevel
Monte










                    Carlo methods for applications in finance (Giles and
                    Szpruch)</a></td>
              </tr>
              <tr>
                <td>May 27, 2014</td>
                <td><a href="http://jakubkonecny.com/">Jakub Konečný</a></td>
                <td> <a href="http://arxiv.org/abs/1402.4419">Incremental
Majorization-Minimization










                    Optimization with Application to Large-Scale Machine
                    Learning</a> (Julien Mairal - 2014)</td>
              </tr>
              <tr>
                <td>May 13, 2014</td>
                <td><a href="http://www.cmap.polytechnique.fr/%7Equ/">Zheng










                    Qu</a></td>
                <td><a
                    href="http://link.springer.com/article/10.1007%2Fs10107-013-0677-5">First-order
methods










                    of smooth convex optimization with inexact oracle
                    (Devolder, Glineur and Nesterov - 2011)</a>.
                  Preprint <a
href="http://www.google.com/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;source=web&amp;cd=1&amp;ved=0CCoQFjAA&amp;url=http%3A%2F%2Fwww.optimization-online.org%2FDB_FILE%2F2010%2F12%2F2865.pdf&amp;ei=Rf9rU6OiDKLY7AaG8YGYBQ&amp;usg=AFQjCNG6mr6-EbWzGzsBqzUTWHc9N5K0nA&amp;sig2=0cRwhpYCX0t5bBZWYRf6Mw&amp;bvm=bv.66330100,d.ZGU&amp;cad=rja">here</a>.</td>
              </tr>
              <tr>
                <td>May 6, 2014</td>
                <td><a
                    href="http://www.maths.ed.ac.uk/%7Es1065527/index.html">Robert
M.










                    Gower</a></td>
                <td><a
                    href="http://www.ece.northwestern.edu/%7Enocedal/PDFfiles/stochBFGS.pdf">A
                    Stochastic Quasi-Newton Method for Large-Scale
                    Optimization (Byrd, Hansen, Nocedal and Singer -
                    2014). </a> Plus maybe also some background from <a
href="http://www.ece.northwestern.edu/%7Enocedal/PDFfiles/ssnewt.pdf">this










                    paper</a>.</td>
              </tr>
              <tr>
                <td>April 30, 2014 </td>
                <td><a href="http://www.maths.ed.ac.uk/%7Eofercoq/">Olivier










                    Fercoq</a></td>
                <td><a href="http://jmlr.org/papers/v12/duchi11a.html">Adaptive
Subgradient










                    Methods for Online Learning <br>
                    and Stochastic Optimization (Duchi, Hazan and Singer
                    - 2011)</a></td>
              </tr>
              <tr>
                <td>April 22, 2014</td>
                <td colspan="2">no meeting (spring break)</td>
              </tr>
              <tr>
                <td>April 15, 2014</td>
                <td colspan="2">no meeting (spring break)</td>
              </tr>
              <tr>
                <td>April 8, 2014</td>
                <td colspan="2">no meeting (spring break)</td>
              </tr>
              <tr>
                <td>April 1, 2014</td>
                <td><a href="http://mtakac.com/">Martin Takáč</a></td>
                <td><a href="http://arxiv.org/abs/1403.4699">A Proximal
                    Stochastic Gradient Method with Progressive Variance
                    Reduction (Xiao and Zhang - 2014)</a></td>
              </tr>
              <tr>
                <td>March 25, 2014</td>
                <td colspan="2">no meeting</td>
              </tr>
              <tr>
                <td>March 18, 2014</td>
                <td><a href="http://jakubkonecny.com/">Jakub Konečný</a></td>
                <td><a href="http://www.ecore.be/DPs/dp_1329823186.pdf">Subgradient
Methods










                    for Huge-Scale Optimization Problems (Nesterov -
                    2012) </a>[<a
                    href="http://link.springer.com/article/10.1007/s10107-013-0686-4">Mathematical
Programming










                    2013</a>]</td>
              </tr>
              <tr>
                <td>March 11, 2014</td>
                <td><a href="http://www.maths.ed.ac.uk/%7Ekfount/">Kimon
                    Fountoulakis</a></td>
                <td><a href="http://arxiv.org/abs/1306.4080">Parallel
                    Coordinate Descent Newton for Efficient
                    L1-Regularized Minimization (Bian, Li, Liu and Yang
                    - 2013)</a></td>
              </tr>
              <tr>
                <td>March 4, 2014</td>
                <td><a href="http://www.see.ed.ac.uk/%7Es0574225/">Mehrdad










                    Yaghoobi</a> </td>
                <td><a
href="http://www.google.com/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;source=web&amp;cd=1&amp;cad=rja&amp;ved=0CCcQFjAA&amp;url=http%3A%2F%2Fmachinelearning.org%2Farchive%2Ficml2008%2Fpapers%2F361.pdf&amp;ei=X0sLU_fwHYi7oQTbqoLoAQ&amp;usg=AFQjCNH-Ck3q1qcn-eOk-QiEMTO2W_xplQ&amp;sig2=-ZquYxKh67vkKfP6Bc7wKw&amp;bvm=bv.61725948,d.cGU">Efficient
Projections










                    onto the L1-Ball for Learning in High Dimensions
                    (Duchi, Shalev-Shwartz, Singer, Chandra - 2008)</a></td>
              </tr>
              <tr>
                <td>Feb 25, 2014</td>
                <td><a href="http://www.cmapx.polytechnique.fr/%7Equ/">Zheng










                    Qu</a></td>
                <td><a
href="http://www.google.com/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;source=web&amp;cd=1&amp;ved=0CCcQFjAA&amp;url=http%3A%2F%2Fwww.ecore.be%2FDPs%2Fdp_1359373295.pdf&amp;ei=yx_xUp-EM9Ou7AaA0IH4Cg&amp;usg=AFQjCNE9bLYSlYgyTDyyzQkFu2IkzqpWdg&amp;sig2=NzQRd7P_SUVyemFCilu8VQ&amp;bvm=bv.60444564,d.ZGU&amp;cad=rja">Finding
the










                    stationary states of Markov chains by iterative
                    methods (Nesterov and Nemirovski - 2013)</a></td>
              </tr>
              <tr>
                <td>Feb 18, 2014</td>
                <td colspan="2">no meeting as many of us will attend <a
href="http://www2.imperial.ac.uk/%7Ebm508/bigdata14.html">this event</a></td>
              </tr>
              <tr>
                <td>Feb 11, 2014</td>
                <td><a href="http://www.maths.ed.ac.uk/%7Eofercoq/">Olivier










                    Fercoq</a></td>
                <td><a href="http://arxiv.org/abs/1305.1922">Efficient
                    Accelerated Coordinate Descent Methods and Faster
                    Algorithms for Solving Linear Systems (Lee and
                    Sidford - 2013)</a></td>
              </tr>
              <tr>
                <td>Feb 4, 2014</td>
                <td><a href="http://www.maths.ed.ac.uk/%7Ertappend/">Rachael
                    Tappenden</a></td>
                <td><a
href="http://www.google.com/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;source=web&amp;cd=2&amp;ved=0CDsQFjAB&amp;url=http%3A%2F%2Fbooks.nips.cc%2Fpapers%2Ffiles%2Fnips25%2FNIPS2012_0026.pdf&amp;ei=KqreUujGHYyShgfzx4DIAw&amp;usg=AFQjCNHjLiM1sjSOyTNB8mtJMCiQZSil0g&amp;sig2=GAvXgrsyk29JN5KgC3w5-g&amp;bvm=bv.59568121,d.ZG4&amp;cad=rja">Feature
Clustering
                    for Accelerating Parallel Coordinate Descent
                    (Sherrer, Tewari, Halappanavar and Haglin - 2012)</a>
                </td>
              </tr>
              <tr>
                <td>Jan 28, 2014</td>
                <td><a href="http://jakubkonecny.com/">Jakub Konečný</a></td>
                <td><a href="http://arxiv.org/abs/1309.2388">Minimizing
                    Finite Sums with the Stochastic Average Gradient
                    (Schmidt, Le Roux and Bach - 2013)</a> </td>
              </tr>
            </tbody>
          </table>
          <br>
          <p><strong>Organizers:</strong> <a
              href="http://jakubkonecny.com/">Jakub Konečný</a> and
            Peter Richtárik</p>
        </div>
        <div style="clear: both;"> </div>
      </div>
      <div id="footer">
        <script src="x_footer.js"></script> </div>
    </div>
  </body>
</html>
